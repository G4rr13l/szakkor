{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cK4TY8M-xt9d"
   },
   "source": [
    "# Deep learning (visszacsatolt hálók)\n",
    "\n",
    "A gyakorlaton egy egyszerű, deep learning-alapú nyelvi modellt valósítunk meg, amellyel magyar nyelvű szövegeket dolgozunk fel. Az implementáció alapját egy visszacsatolt neurális háló adja, amelyet a szövegben soron következő karakter predikciójára tanítunk (a korábban megfigyelt karaktereket, mint bemenetet felhasználva). A tanult modellt ezután szöveg generálására használjuk fel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "TPkT1IQsxvj0",
    "outputId": "39fc5617-a1c4-4330-abe3-3d13f2948291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZiDtYSvz4PN"
   },
   "source": [
    "## 1. Bemeneti adatok előállítása\n",
    "\n",
    "A karaktereket one-hot módon kódoljuk. Minden karaktert egy $\\left\\lbrace 0,1\\right\\rbrace^d$ vektorral reprezentálunk, ahol például\n",
    "\n",
    "\\begin{align}\n",
    "\\text{'a'} &= \\left[1, 0, 0, \\dots, 0 \\right], \\\\\n",
    "\\text{'b'} &= \\left[0, 1, 0, \\dots, 0 \\right], \\\\\n",
    "& \\vdots \\\\\n",
    "\\text{'Z'} &= \\left[0, 0, 0, \\dots, 1 \\right], \\\\\n",
    "\\end{align}\n",
    "\n",
    "A visszacsatolt hálózat bemenetére egy $\\left(n,m,d\\right)$ méretű, kimenetére egy $\\left(n,d\\right)$ méretű tenzor kerül, ahol \n",
    "\n",
    "- $n$ a tanítóminták száma\n",
    "- Minden tanítómintában van a teljes szövegnek egy $m$ hosszú rész-szekvenciája, amelynek minden karakterét az előbb látott $d$-dimenziós vektorokkal kódoljuk (bemenet)\n",
    "- Minden tanítómintában található egy $d$-dimenziós vektor (kimenet), amely az előbbi rész-szekvencia utáni első rákövetkező karaktert reprezentálja.\n",
    "\n",
    "A tanítómintákat úgy generáljuk, hogy ezt az $m$ széles ablakot végigtoljuk a teljes szövegen. Összefoglalva, a háló a bemenet-kimenet összefüggés becslése során $m$ lépésnyit tekint vissza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjVRF6gh2bR-"
   },
   "outputs": [],
   "source": [
    "url = \"https://www.mit.bme.hu/system/files/oktatas/targyak/10142/telep.txt\" # nevek.txt, telep.txt\n",
    "seq = urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eu8akt6vz5z4"
   },
   "source": [
    "<b>1.1. feladat.</b> Hozzon létre egy kódoló és dekódoló dictionary-t a one-hot kódoláshoz (azaz előbbiben minden egyedi karakterhez szerepeljen egy egyedi $d$-nél kisebb szám, utóbbi legyen az előbbi inverze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5azI28Zzz4u"
   },
   "outputs": [],
   "source": [
    "chars = set(seq)\n",
    "d     = len(chars)\n",
    "\n",
    "encoding = dict(zip(chars,range(d)))\n",
    "decoding = dict(zip(range(d),chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yiQ1vsww0G0m"
   },
   "source": [
    "<b>1.2. feladat.</b> Alkalmas $m$ választása mellett hozza létre háló bemenetére kerülő $(n,m,d)$ méretű tenzort, valamint a kimenetet reprezentáló $(n,d)$ méretű tenzort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4M5_2mR00DgX"
   },
   "outputs": [],
   "source": [
    "l = len(seq)\n",
    "m = 32\n",
    "w = 1\n",
    "n = (l-m)//w\n",
    "\n",
    "chars_in  = np.zeros((n,m,d),dtype=np.bool)\n",
    "chars_out = np.zeros((n,d),dtype=np.bool)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        chars_in[i,j,encoding[seq[i*w+j]]] = 1\n",
    "    chars_out[i,encoding[seq[i*w+m]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8PkL43_0M6M"
   },
   "source": [
    "## 2. Visszacsatolt háló létrehozása\n",
    "\n",
    "A hálózathoz tetszőleges architektúrát használhatunk, de ügyelnünk kell arra, hogy a hálózat kimenete kompatibilis legyen az előző lépésben létrehozott kimenettel, azaz a kimenet mérete legyen $d$ (ehhez például illeszthetünk egy teljesen összekötött réteget a visszacsatolt réteg után). Mivel lényegében többosztályos osztályozást végzünk, a veszteségfüggvényt és aktivációs függvényt is ennek megfelelően kell megválasztani. A hálózat létrehozásához itt talál segítséget:\n",
    "\n",
    "https://keras.io/\n",
    "\n",
    "(pl. Input, LSTM/GRU/SimpleRNN, Dense rétegek)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTIYk5R10Qh4"
   },
   "source": [
    "<b>2.1. feladat.</b> Hozzon létre a követelményeknek megfelelő neurális hálózatot, majd hozzon létre egy modellt (használja a <i>tf.keras.Model()</i> és  osztályt és ennek a <i>tf.keras.Model.compile()</i> metódusát)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADeHoHs00TpZ"
   },
   "outputs": [],
   "source": [
    "inp   = tf.keras.layers.Input(shape=(m,d))\n",
    "net   = tf.keras.layers.LSTM(128,dropout=0.5,recurrent_dropout=0.5)(inp)\n",
    "net   = tf.keras.layers.Dense(d,activation=tf.nn.softmax)(net)\n",
    "model = tf.keras.Model(inp,net)\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer=tf.keras.optimizers.RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zgn4oFia0V11"
   },
   "source": [
    "<b>2.2. feladat.</b> Végezze el a tanítást (<i>tf.keras.Model.fit()</i> függvény)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UPXMrUAB0dD3",
    "outputId": "11748599-7dd4-4ccb-93a6-2437a9e16c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.7255\n",
      "Epoch 2/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.5570\n",
      "Epoch 3/50\n",
      "29984/29984 [==============================] - 4s 143us/sample - loss: 2.4855\n",
      "Epoch 4/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.4266\n",
      "Epoch 5/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.3828\n",
      "Epoch 6/50\n",
      "29984/29984 [==============================] - 4s 148us/sample - loss: 2.3538\n",
      "Epoch 7/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.3293\n",
      "Epoch 8/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.3068\n",
      "Epoch 9/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.2928\n",
      "Epoch 10/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.2797\n",
      "Epoch 11/50\n",
      "29984/29984 [==============================] - 4s 148us/sample - loss: 2.2664\n",
      "Epoch 12/50\n",
      "29984/29984 [==============================] - 4s 143us/sample - loss: 2.2523\n",
      "Epoch 13/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.2403\n",
      "Epoch 14/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.2335\n",
      "Epoch 15/50\n",
      "29984/29984 [==============================] - 4s 137us/sample - loss: 2.2243\n",
      "Epoch 16/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.2174\n",
      "Epoch 17/50\n",
      "29984/29984 [==============================] - 4s 139us/sample - loss: 2.2146\n",
      "Epoch 18/50\n",
      "29984/29984 [==============================] - 4s 138us/sample - loss: 2.2036\n",
      "Epoch 19/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.2023\n",
      "Epoch 20/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.1905\n",
      "Epoch 21/50\n",
      "29984/29984 [==============================] - 4s 143us/sample - loss: 2.1902\n",
      "Epoch 22/50\n",
      "29984/29984 [==============================] - 4s 147us/sample - loss: 2.1843\n",
      "Epoch 23/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.1774\n",
      "Epoch 24/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1752\n",
      "Epoch 25/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1717\n",
      "Epoch 26/50\n",
      "29984/29984 [==============================] - 4s 145us/sample - loss: 2.1615\n",
      "Epoch 27/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1596\n",
      "Epoch 28/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1598\n",
      "Epoch 29/50\n",
      "29984/29984 [==============================] - 4s 143us/sample - loss: 2.1511\n",
      "Epoch 30/50\n",
      "29984/29984 [==============================] - 4s 143us/sample - loss: 2.1500\n",
      "Epoch 31/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1535\n",
      "Epoch 32/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1523\n",
      "Epoch 33/50\n",
      "29984/29984 [==============================] - 4s 144us/sample - loss: 2.1470\n",
      "Epoch 34/50\n",
      "29984/29984 [==============================] - 4s 138us/sample - loss: 2.1402\n",
      "Epoch 35/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1364\n",
      "Epoch 36/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1429\n",
      "Epoch 37/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1344\n",
      "Epoch 38/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1409\n",
      "Epoch 39/50\n",
      "29984/29984 [==============================] - 4s 148us/sample - loss: 2.1289\n",
      "Epoch 40/50\n",
      "29984/29984 [==============================] - 4s 145us/sample - loss: 2.1290\n",
      "Epoch 41/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.1289\n",
      "Epoch 42/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.1268\n",
      "Epoch 43/50\n",
      "29984/29984 [==============================] - 4s 140us/sample - loss: 2.1259\n",
      "Epoch 44/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1235\n",
      "Epoch 45/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1199\n",
      "Epoch 46/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1230\n",
      "Epoch 47/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1128\n",
      "Epoch 48/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1247\n",
      "Epoch 49/50\n",
      "29984/29984 [==============================] - 4s 141us/sample - loss: 2.1141\n",
      "Epoch 50/50\n",
      "29984/29984 [==============================] - 4s 142us/sample - loss: 2.1096\n"
     ]
    }
   ],
   "source": [
    "model.fit(chars_in,chars_out,epochs=50,batch_size=256);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MvoahOk0odP"
   },
   "source": [
    "## 3. Szöveg generálása\n",
    "\n",
    "A szöveg generálásához a következőképpen járhatunk el:\n",
    "\n",
    "- Az első bemenetet létrehozhatjuk tetszőlegesen (pl. a szöveg egy részlete)\n",
    "- Ezen bemenetet a tanult modellre ráadva megkapjuk a rákövetkező karakter eloszlását\n",
    "- Az eloszlásból mintavételezzük a rákövetkező karaktert, amit ki is írunk\n",
    "- A bemenetet shifteljük (az utolsó helyre az imént kapott karakter kerül, az első pedig kiesik)\n",
    "\n",
    "Ezt tetszőleges ideig ismételgetjük."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_wRswj20p-e"
   },
   "source": [
    "<b>3.1. feladat.</b> Generáljon 200 karakternyi szöveget a tanult modell felhasználásával. Variálja az architektúrát, dokumentálja a tapasztaltakat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "Xo4OZMZs0iE0",
    "outputId": "8090e13d-1718-4b6b-ec10-401333b14299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répényszentbarlán\n",
      "Nemesszentgyörgyös\n",
      "Tágonypötk\n",
      "Oztverkék\n",
      "Vémenke\n",
      "Vejentpéthely\n",
      "Szobageresztamjér\n",
      "Sápos\n",
      "Zalaszentmihály\n",
      "Govácsvállós\n",
      "Győrcgycsakás\n",
      "Hejcs\n",
      "Kegyházasú\n",
      "Fommónos\n",
      "Zilasziget\n",
      "Nyírrács\n",
      "Kispará\n"
     ]
    }
   ],
   "source": [
    "pred = np.zeros((1,m,d),dtype=np.bool)\n",
    "pred[0,-1,encoding['\\n']] = 1\n",
    "out = \"\"\n",
    "for i in range(200):\n",
    "    pr = np.random.choice(range(d),p=model.predict(pred)[0])\n",
    "    pred = np.roll(pred,-1,1)\n",
    "    pred[0,-1,:] = np.zeros(d)\n",
    "    pred[0,-1,pr] = 1\n",
    "    out += decoding[pr]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2x1-lQEJ0vJg"
   },
   "source": [
    "<b>3.2. szorgalmi.</b> Hozzon létre és tanítson egy bonyolultabb nyelvi modellt, amely hosszabb szövegek, pl. könyvek generálására is alkalmas."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3_solved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
